{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaee9cfa",
   "metadata": {},
   "source": [
    "#### The scope of this project is to apply LSTM to predict the returns for 7 high-growth assets. Most of these stocks are tech stock that have extremely high returns during the bull run 2016-2025 so their average returns are unrealisticly high. LSTM will shrink these returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891b4e81-5ca3-4188-be98-36ed52b4dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8caa3ec8-6df1-4f41-8920-50d9653f9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 7 high-growth assets\n",
    "tickers=[\"HWM\", \"NVDA\", \"MSI\", \"AMZN\", \"MA\", \"TSLA\", \"ALB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161e1cf2-ce33-4340-9f48-1cc8cc813068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/71bzq9451kqf888zy5kpswfr0000gn/T/ipykernel_66128/2425981317.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  prices = yf.download(tickers, start=\"2016-11-01\", end=\"2025-09-02\",interval=\"1mo\")[\"Close\"]\n",
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "source": [
    "prices = yf.download(tickers, start=\"2016-11-01\", end=\"2025-09-02\",interval=\"1mo\")[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3481162c-3d11-46d5-9492-954b40462bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = np.log(prices).diff().dropna() #returns of each asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dac82-5b38-4a1f-9d7d-b9aa9ad09391",
   "metadata": {},
   "source": [
    "---\n",
    "# Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f73c9",
   "metadata": {},
   "source": [
    "This model is simply an LSTM model using historical returns to predict future return. Simply a time series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dedc104-86c4-47fd-9710-f0052bf9d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(X_df, y_df, lookback=12):\n",
    "    X_list, y_list = [], []\n",
    "    for i in range(len(X_df)-lookback):\n",
    "        X_window = X_df.iloc[i:i+lookback].values     # (L, n_features)\n",
    "        y_next   = y_df.iloc[i+lookback].values       # (n_tickers,)\n",
    "        X_list.append(X_window)\n",
    "        y_list.append(y_next)\n",
    "    return np.array(X_list, dtype=\"float32\"), np.array(y_list, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98250cff-e8a9-42d3-a64a-008cb737dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base = returns.copy()\n",
    "y_base = returns.shift(-1).dropna()\n",
    "X_base = X_base.loc[y_base.index]  # align or, in this case, drop the last month because there's no y for that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c60ca5ba-92e8-4f13-b369-21095785e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model: pure historical prices\n",
    "Xb, yb = make_sequences(X_base, y_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf3b1a8-828c-45e0-929b-9e048f525578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_split(X, y, val_size=0.2):\n",
    "    split = int(len(X)*(1-val_size))\n",
    "    return X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "Xtr_base, Xval_base, ytr_base, yval_base = train_val_split(Xb, yb)\n",
    "\n",
    "# scale\n",
    "sc_X, sc_y = StandardScaler(), StandardScaler()\n",
    "Xtr_base = sc_X.fit_transform(Xtr_base.reshape(-1, Xtr_base.shape[2])).reshape(Xtr_base.shape)\n",
    "Xval_base = sc_X.transform(Xval_base.reshape(-1, Xval_base.shape[2])).reshape(Xval_base.shape)\n",
    "\n",
    "ytr_base = sc_y.fit_transform(ytr_base)   # (Ntr, 7)\n",
    "yval_base = sc_y.transform(yval_base)     # (Nval, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7c2cd0-daff-416f-8d04-b8166a40cd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/banguyen/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(7)   # target return for 7 assets\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "model = build_model((Xtr_base.shape[1], Xtr_base.shape[2])) #Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab73a525-6be8-4131-8477-900252930bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m18,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m119\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,495</span> (123.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,495\u001b[0m (123.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,495</span> (123.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,495\u001b[0m (123.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44130051-4ce8-4397-8572-85188ca30101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 1.0045 - val_loss: 0.5391 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9894 - val_loss: 0.5363 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9839 - val_loss: 0.5366 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9745 - val_loss: 0.5386 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9660 - val_loss: 0.5416 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9554 - val_loss: 0.5440 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9463 - val_loss: 0.5493 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9403 - val_loss: 0.5532 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9348 - val_loss: 0.5583 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9284 - val_loss: 0.5637 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9252 - val_loss: 0.5683 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.9199 - val_loss: 0.5729 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "rlr = ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-5)\n",
    "\n",
    "base = model.fit(\n",
    "    Xtr_base, ytr_base,\n",
    "    validation_data=(Xval_base, yval_base),\n",
    "    epochs=200,\n",
    "    batch_size=8,\n",
    "    shuffle=False,  # keep time order\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab4d64",
   "metadata": {},
   "source": [
    "Our model stops after 12 epoches with very small learning rates for each epoch and the loss is only slightly reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ef0df5c-0a3d-4e79-987d-caa5ffebdd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Predict on validation X (scaled) → invert y scaling\n",
    "yval_pred_scaled = model.predict(Xval_base, verbose=0)          # shape (Nval, 7)\n",
    "yval_pred = sc_y.inverse_transform(yval_pred_scaled)        # real returns\n",
    "yval_true = sc_y.inverse_transform(yval_base)                    # real returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db1ce80-9a3e-4c91-9a06-2e5e673146d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HWM': {'RMSE': np.float64(0.11855187891943722),\n",
       "  'MAE': 0.09139399975538254,\n",
       "  'R2': -0.03265273571014404,\n",
       "  'DirAcc': np.float64(0.5789473684210527)},\n",
       " 'NVDA': {'RMSE': np.float64(0.06452652696293114),\n",
       "  'MAE': 0.05436856672167778,\n",
       "  'R2': -0.00507962703704834,\n",
       "  'DirAcc': np.float64(0.631578947368421)},\n",
       " 'MSI': {'RMSE': np.float64(0.10450831404693452),\n",
       "  'MAE': 0.08156838268041611,\n",
       "  'R2': -0.14600491523742676,\n",
       "  'DirAcc': np.float64(0.631578947368421)},\n",
       " 'AMZN': {'RMSE': np.float64(0.03841248388995703),\n",
       "  'MAE': 0.03206741809844971,\n",
       "  'R2': -0.016925811767578125,\n",
       "  'DirAcc': np.float64(0.5789473684210527)},\n",
       " 'MA': {'RMSE': np.float64(0.052758348278656275),\n",
       "  'MAE': 0.041712310165166855,\n",
       "  'R2': -0.001048445701599121,\n",
       "  'DirAcc': np.float64(0.7368421052631579)},\n",
       " 'TSLA': {'RMSE': np.float64(0.10130987476534017),\n",
       "  'MAE': 0.08297139406204224,\n",
       "  'R2': 0.002702772617340088,\n",
       "  'DirAcc': np.float64(0.631578947368421)},\n",
       " 'ALB': {'RMSE': np.float64(0.14692626423716182),\n",
       "  'MAE': 0.11706003546714783,\n",
       "  'R2': -0.011413335800170898,\n",
       "  'DirAcc': np.float64(0.5789473684210527)}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_ticker = {}\n",
    "for j, t in enumerate(tickers):\n",
    "    rmse_j = np.sqrt(mean_squared_error(yval_true[:, j], yval_pred[:, j]))\n",
    "    mae_j  = mean_absolute_error(yval_true[:, j], yval_pred[:, j])\n",
    "    r2_j   = r2_score(yval_true[:, j], yval_pred[:, j])\n",
    "    dir_j  = (np.sign(yval_pred[:, j]) == np.sign(yval_true[:, j])).mean()\n",
    "    per_ticker[t] = dict(RMSE=rmse_j, MAE=mae_j, R2=r2_j, DirAcc=dir_j)\n",
    "per_ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd361e9-470a-4be0-8e00-1f33f8cc1bd7",
   "metadata": {},
   "source": [
    "This model does a slightly-better-than-random. It's not good enough to replace the mean baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f5c6d-0b6b-4c00-89a4-9383dc04a1e7",
   "metadata": {},
   "source": [
    "---\n",
    "## Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3415d",
   "metadata": {},
   "source": [
    "This model is similar to the first one, but we will add some indicators, which are tied directly to the prices, so maybe a bit different but the base of the model is still the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2910f86d-5dfa-4711-bacc-5b682bbdcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66def7e-6eb9-4378-970b-8ae49295078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for t in tickers:\n",
    "    ind = pd.DataFrame(index=prices.index)\n",
    "    ind[f\"{t}_ret\"] = returns[t]\n",
    "    \n",
    "    # Example indicators\n",
    "    ind[f\"{t}_rsi\"] = ta.momentum.RSIIndicator(prices[t]).rsi()\n",
    "    ind[f\"{t}_sma20\"] = ta.trend.SMAIndicator(prices[t], window=20).sma_indicator()\n",
    "    ind[f\"{t}_sma50\"] = ta.trend.SMAIndicator(prices[t], window=50).sma_indicator()\n",
    "    ind[f\"{t}_macd\"] = ta.trend.MACD(prices[t]).macd()\n",
    "    ind[f\"{t}_bb_high\"] = ta.volatility.BollingerBands(prices[t]).bollinger_hband()\n",
    "    ind[f\"{t}_bb_low\"]  = ta.volatility.BollingerBands(prices[t]).bollinger_lband()\n",
    "    \n",
    "    features.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c54044-37c1-48fd-8e28-d97552837c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat(features, axis=1).dropna()\n",
    "y_full = returns.loc[X_full.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b889568-a7db-4db2-bbe8-f922926da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ind, y_ind = make_sequences(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f4b888-a615-4b8c-9f97-e3ca02847797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 6. Train/validation split ======\n",
    "split = int(len(X_ind)*0.8)\n",
    "Xtr_ind, Xval_ind = X_ind[:split], X_ind[split:]\n",
    "ytr_ind, yval_ind = y_ind[:split], y_ind[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d5339ad-df17-479b-9b81-b4b7adb16eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 7. Scale features ======\n",
    "Xtr_ind = sc_X.fit_transform(Xtr_ind.reshape(-1, Xtr_ind.shape[2])).reshape(Xtr_ind.shape)\n",
    "Xval_ind = sc_X.transform(Xval_ind.reshape(-1, Xval_ind.shape[2])).reshape(Xval_ind.shape)\n",
    "ytr_ind = sc_y.fit_transform(ytr_ind)\n",
    "yval_ind = sc_y.transform(yval_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b17164a-98b0-46d2-b402-bd8f103c4514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 49 ; n_assets: 7 ; seq_len: 12\n"
     ]
    }
   ],
   "source": [
    "# ====== 8. Define multi-output LSTM ======\n",
    "n_features = X_ind.shape[2]\n",
    "n_assets = y_ind.shape[1]\n",
    "seq_len = X_ind.shape[1]\n",
    "print(\"n_features:\", n_features, \"; n_assets:\", n_assets, \"; seq_len:\", seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff151ba0-5f39-4f0b-850b-2bc8eb87209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/banguyen/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 1.0179 - val_loss: 0.6436 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9835 - val_loss: 0.6467 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9607 - val_loss: 0.6584 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9439 - val_loss: 0.6744 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9438 - val_loss: 0.6879 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9361 - val_loss: 0.6928 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9278 - val_loss: 0.6955 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9192 - val_loss: 0.6969 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9153 - val_loss: 0.7001 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9249 - val_loss: 0.7057 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model((Xtr_ind.shape[1], Xtr_ind.shape[2])) #Model 2\n",
    "history_ind = model2.fit(\n",
    "    Xtr_ind, ytr_ind,\n",
    "    validation_data=(Xval_ind, yval_ind),\n",
    "    epochs=200,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    callbacks=[es, rlr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6faaa5c-bddc-4445-92e9-50f087c57701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "{'HWM': {'RMSE': 0.01740124262869358, 'MAE': 0.1021505743265152, 'R2': -0.011916875839233398, 'DirAcc': np.float64(0.7)}, 'NVDA': {'RMSE': 0.005388725083321333, 'MAE': 0.06562988460063934, 'R2': 0.017145216464996338, 'DirAcc': np.float64(0.4)}, 'MSI': {'RMSE': 0.0080042639747262, 'MAE': 0.07811928540468216, 'R2': -0.05521583557128906, 'DirAcc': np.float64(0.6)}, 'AMZN': {'RMSE': 0.0015459759160876274, 'MAE': 0.033508043736219406, 'R2': -0.020122766494750977, 'DirAcc': np.float64(0.5)}, 'MA': {'RMSE': 0.003343359101563692, 'MAE': 0.045809995383024216, 'R2': -0.5446550846099854, 'DirAcc': np.float64(0.6)}, 'TSLA': {'RMSE': 0.012073269113898277, 'MAE': 0.0941978469491005, 'R2': -0.024521350860595703, 'DirAcc': np.float64(0.5)}, 'ALB': {'RMSE': 0.022078534588217735, 'MAE': 0.11610134690999985, 'R2': -0.05424630641937256, 'DirAcc': np.float64(0.5)}}\n"
     ]
    }
   ],
   "source": [
    "# ====== 11. Predict & evaluate ======\n",
    "yval_pred_ind = model2.predict(Xval_ind)\n",
    "yval_pred_ind = sc_y.inverse_transform(yval_pred_ind)\n",
    "yval_true_ind = sc_y.inverse_transform(yval_ind)\n",
    "\n",
    "results = {}\n",
    "for i, ticker in enumerate(tickers):\n",
    "    results[ticker] = {\n",
    "        \"RMSE\": mean_squared_error(yval_true_ind[:,i], yval_pred_ind[:,i]),\n",
    "        \"MAE\": mean_absolute_error(yval_true_ind[:,i], yval_pred_ind[:,i]),\n",
    "        \"R2\": r2_score(yval_true_ind[:,i], yval_pred_ind[:,i]),\n",
    "        \"DirAcc\": np.mean(np.sign(yval_true_ind[:,i]) == np.sign(yval_pred_ind[:,i]))\n",
    "    }\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0b207",
   "metadata": {},
   "source": [
    "This model's performance is no better than the first one, if not worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a86321-5a16-4c93-931d-d96a5d3552c2",
   "metadata": {},
   "source": [
    "Except for HWM the model is almost random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b078f4-fd6b-46c2-85f2-00476abbfa35",
   "metadata": {},
   "source": [
    "--- \n",
    "# Relative assets (competitors & market movers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb6fc8-e58a-4561-af8a-64448fd44338",
   "metadata": {},
   "source": [
    "We will train 7 seperated models to predict the returns for each assets separatedly with the same set of relative assets. \n",
    "Ten relative assets include:\n",
    "1. SPY (S&P500): broad US market\n",
    "2. QQQ: tech heavy, captures growth\n",
    "3. XLK: technology sector (NVDA, TSLA, MA, MSI)\n",
    "4. XLY: consumer discretionary (AMZN, TSLA)\n",
    "5. XLF: financials (MA, MSI partly)\n",
    "6. XLI: industrials (HWM, aerospace/defense)\n",
    "7. XLB: materials (ALB)\n",
    "8. SMH: semiconductors ETF (NVDA, indirectly TSLA/autonomous)\n",
    "9. ITA: aerospace & defense (HWM)\n",
    "10. LIT: lithium/battery ETF (ALB, TSLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ec85cb3-88eb-4778-bd25-b9c6d0a43921",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a=[\"SPY\",\"QQQ\",\"XLK\",\"XLY\",\"XLI\",\"XLF\",\"XLB\",\"SMH\",\"ITA\",\"LIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5161c9ad-d832-43e6-ad00-8f068effbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/71bzq9451kqf888zy5kpswfr0000gn/T/ipykernel_66128/2914001459.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  relatives = yf.download(r_a, start=\"2016-11-01\", end=\"2025-09-02\",interval=\"1mo\")[\"Close\"]\n",
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "relatives = yf.download(r_a, start=\"2016-11-01\", end=\"2025-09-02\",interval=\"1mo\")[\"Close\"]\n",
    "ra_returns=relatives.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "273d622e-7a7e-4132-be0c-bd1ee3f8da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ra, y_ra = make_sequences(ra_returns, returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffb13df1-032b-469f-b2ef-46d7e2a50f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 12, 10) (94, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_ra.shape,y_ra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d963a24-46a8-4bb0-95fd-b3a0e06d12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8*len(X_ra))\n",
    "Xtr_ra, Xval_ra = X_ra[:split], X_ra[split:]\n",
    "ytr_ra, yval_ra = y_ra[:split], y_ra[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e56f755-1ee7-491c-b70e-215c94a92296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/banguyen/miniconda3/lib/python3.13/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_ra=build_model((X_ra.shape[1],X_ra.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f010e223-ee12-4f79-befc-4ba180a062ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0165 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0163 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0161 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0160 - val_loss: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0160 - val_loss: 0.0096 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0159 - val_loss: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0159 - val_loss: 0.0094 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0158 - val_loss: 0.0094 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0158 - val_loss: 0.0095 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0159 - val_loss: 0.0095 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0158 - val_loss: 0.0094 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1435aa0d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ra.fit(Xtr_ra, ytr_ra,\n",
    "          validation_data=(Xval_ra, yval_ra),\n",
    "          epochs=200, batch_size=8,\n",
    "          callbacks=[es, rlr],\n",
    "          verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94b5339c-7819-41cc-8cb9-56ef5c02fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "{'Asset_1': {'RMSE': np.float64(0.12052497803340285), 'MAE': 0.09314992278814316, 'R2': -0.06731224060058594, 'DirAcc': np.float64(0.42105263157894735)}, 'Asset_2': {'RMSE': np.float64(0.0644192064508844), 'MAE': 0.05441601574420929, 'R2': -0.0017391443252563477, 'DirAcc': np.float64(0.631578947368421)}, 'Asset_3': {'RMSE': np.float64(0.10196750839031625), 'MAE': 0.08067941665649414, 'R2': -0.09095895290374756, 'DirAcc': np.float64(0.631578947368421)}, 'Asset_4': {'RMSE': np.float64(0.03802192792693993), 'MAE': 0.03198592737317085, 'R2': 0.003648042678833008, 'DirAcc': np.float64(0.5789473684210527)}, 'Asset_5': {'RMSE': np.float64(0.05375138623715002), 'MAE': 0.04291767627000809, 'R2': -0.03908729553222656, 'DirAcc': np.float64(0.7368421052631579)}, 'Asset_6': {'RMSE': np.float64(0.10201295124107705), 'MAE': 0.08346647024154663, 'R2': -0.011187553405761719, 'DirAcc': np.float64(0.631578947368421)}, 'Asset_7': {'RMSE': np.float64(0.1464705587865061), 'MAE': 0.11696881055831909, 'R2': -0.005149245262145996, 'DirAcc': np.float64(0.5789473684210527)}}\n"
     ]
    }
   ],
   "source": [
    "yval_pred_ra = model_ra.predict(Xval_ra)\n",
    "def evaluate_multi(y_true, y_pred):\n",
    "    n_assets = y_true.shape[1]\n",
    "    results = {}\n",
    "    \n",
    "    for i in range(n_assets):\n",
    "        results[f\"Asset_{i+1}\"] = {\n",
    "            \"RMSE\": np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i])),\n",
    "            \"MAE\": mean_absolute_error(y_true[:, i], y_pred[:, i]),\n",
    "            \"R2\": r2_score(y_true[:, i], y_pred[:, i]),\n",
    "            \"DirAcc\": np.mean(np.sign(y_true[:, i]) == np.sign(y_pred[:, i]))\n",
    "        }\n",
    "    return results\n",
    "\n",
    "print(evaluate_multi(yval_ra, yval_pred_ra))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea0a02",
   "metadata": {},
   "source": [
    "This performance is somewhat similar to the first model, if not worse. We understand that stocks are random and historical prices are noise. For that reason, to even predict about 25% of the exact returns seems impossible. Still, we will incorporate these predictions to balance out the average returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6510e757-0a4d-4baf-9ee6-74da4a8d97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "lookback=12\n",
    "last_window = returns[-lookback:].values   # shape (12, 7)\n",
    "last_window = last_window.reshape(1, lookback, 7)  # add batch dim\n",
    "\n",
    "# Step 3: Predict next month\n",
    "next_pred_scaled = model.predict(last_window)  # shape (1, 7)\n",
    "next_pred = sc_y.inverse_transform(next_pred_scaled)  # rescale\n",
    "\n",
    "# Step 4: Iterative forecasting (e.g., 6 months ahead)\n",
    "future_preds = []\n",
    "window = last_window.copy()\n",
    "\n",
    "for _ in range(6):  # forecast 6 months\n",
    "    pred_scaled = model.predict(window)\n",
    "    pred = sc_y.inverse_transform(pred_scaled)\n",
    "    future_preds.append(pred.ravel())\n",
    "\n",
    "    # roll the window forward: drop oldest, add prediction\n",
    "    new_row = pred_scaled  # keep in scaled space for model input\n",
    "    window = np.concatenate([window[:,1:,:], new_row.reshape(1,1,7)], axis=1)\n",
    "\n",
    "future_preds = np.array(future_preds)  # shape (6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a7af52d-f088-41da-a43f-b0b83d8a03e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(-0.023349298),\n",
       " np.float32(0.003958315),\n",
       " np.float32(0.04078467),\n",
       " np.float32(0.015256338),\n",
       " np.float32(0.020482888),\n",
       " np.float32(0.043185662),\n",
       " np.float32(-0.0031317333)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.mean() for r in future_preds.T]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pm-ml)",
   "language": "python",
   "name": "pm-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
